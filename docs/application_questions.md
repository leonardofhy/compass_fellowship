# Compass Fellowship Taiwan 2026 Application

 **The Compass Fellowship** is a free 5-day live-in program hosted in Taipei. It is for curious and ambitious university students interested in reflecting, exploring, and changing themselves and the world. 

## Key Dates & Logistics

- **Application Due Date:** January 3rd, 2026 at 11:59pm Taiwan Time (GMT+8)
- **Admissions:** Rolling basis. The first stage is this application, the second stage is a ~45 minute interview.
- **Notification:** You should expect to hear back for an interview in 1-2 week's time.

### Program Dates
- **First Run:** January 24 - January 29, 2026 (leaving morning of 29th)
- **Second Run:** February 2 - February 7, 2026 (leaving morning of 7th)

> There was an error in some previous materials showing Feb 1 - 6 for the second cohort. The correct dates are February 2 - 7. Apologies for any inconvenience!

## Eligibility

- **Age:** 18 to 23 years old as of January 24, 2026.
- **Criteria:** We are looking for applicants to demonstrate an interest and/or capacity for **open and curious inquiry**, **model that which is familiar and unfamiliar**, and **introspective awareness**.
- **No Hard Requirements:** No specific GPA or major required.
- **Language:** The program will be run in English. Recommended that you are comfortable and excited to participate in an English speaking environment.

> *如果你認為用中文填答能更佳展現個人優勢，我們也很歡迎。但要留意，並非所有審評人員都精通中文，因此在翻譯過程中，可能有些意涵無法完整傳達。*

---

## Basic Information

**Tell us some basic details about yourself so we can know about your availability for the program and help us compose a good cohort.**

- **Email:** `leonardofoohy@gmail.com`
- **Full Name:** Leonardo Foo Haw Yang
- **Age (as of Jan 24, 2026):** 27 *(Note: Eligibility states 18-23, user input is 27)*
- **Gender:** Male
- **Current Location:** Taiwan
- **Availability:** No Preference, Both Can Work (Jan 24 - 29 or Feb 2 - 7)
- **LinkedIn/Website:** [https://www.linkedin.com/in/leonardo-fhy/](https://www.linkedin.com/in/leonardo-fhy/)
- **CV/Resume:** `Leonardo_Foo_Haw_Yang_Resume_20251213.pdf`

---

## Evaluative Questions

**Help us learn more about how you think about and approach the world, others, and yourself.**

*All questions are optional. We recommend responding to two or more questions and keeping responses to within 300 words. We would be happy to receive a "partial" answer on a question. We want to see the process of your thinking.*

### 1. What's something you would like to understand better? How do you hope to achieve this?

<details>
<summary>💡 策略提示（點擊展開）</summary>

這題測試你的「建模能力」和「真正的好奇心」。選一個智識上有深度的主題，避免純粹職涯導向的答案。

</details>

---

**📝 Draft Answer (v1):**

**📝 草稿回答 (中文版):**

我想理解不同的利益相關者如何在 AI 發展上進行協調，而不陷入僵局。

這個問題源於我在 **台灣國家級 LLM 專案 (TAIDE)** 的一段具體掙扎。我們的目標是訓練一個「台灣在地化」的模型，但我們撞上了一堵牆：繁體中文資料只佔全球中文資料的不到 0.01%。

這不僅僅是一個技術問題，更是一個**價值觀的衝突**。
為了追求**能力 (Capability)**，工程邏輯告訴我們必須引入來自中國的大量互聯網數據，否則模型會變笨。
但為了追求**對齊 (Alignment)**，政治邏輯告訴我們這很危險——模型可能會學到「台灣是中國的一部分」這種由於數據偏差 (Data Bias) 產生的立場，這對於一個國家級模型來說是不可接受的。

這讓我深刻體會到，所謂的「AI 發展」其實是一場在**追求真理（學術界/數據科學）**、**追求效率（產業界）**與**追求正當性（政府）**之間不斷妥協的賽局。我目前的困惑是：我們是否有更好的協調機制，而不僅僅是依賴這種痛苦的權衡 (Trade-off)？

這是我希望透過結合**利益相關者建模**與**歷史研究**來尋找答案的原因。


Draft v2

**📝 草稿回答 (中文版):**

我想理解 LLM 這個「黑盒子」內部到底發生了什麼——它是如何從海量的文本統計中，湧現出看似「推理」甚至「理解」的行為的？

這個好奇心源於我在 AI 研究中的困惑。我可以訓練一個模型，讓它在各種任務上表現得很好，但我其實不太「理解」它為什麼能做到這些。這讓我感到不安：如果我們打算把越來越多的決策交給這些系統，但我們卻不知道它們內部在做什麼，這是否是一種盲目的信任？

對我來說，這不只是技術問題，更是 AI Safety 的核心。真正的「對齊 (Alignment)」不可能建立在黑盒子之上——如果我們不知道模型在「想」什麼，我們就沒辦法確保它與人類價值觀一致。

我計劃透過以下方式來探索這個問題：首先，深入學習 Mechanistic Interpretability 這個子領域，閱讀 Anthropic、DeepMind 等團隊關於模型內部機制的研究；其次，在我自己的實驗中嘗試追蹤模型內部的激活模式 (Activation Patterns)，看看特定的「能力」是如何在神經網路中被編碼的；最後，參與 AI Safety 社群的討論，與其他研究者交流對這個問題的理解。

Draft v3

我想理解 AI 模型這個黑盒子內部的實際運作模式。目前 AI 研究依然無法解釋深度學習模型為什麼有效，大多數時候都是通過做實驗的方式進行驗證。但只通過做實驗並不能解釋為什麼有時候模型表現更好或更糟。這其實是個可怕的事情，特別是今天 AI 對我們的社會已經產生了巨大的影響，我們如果不研究 AI 模型的機制，就沒辦法做好 AI Safety，特別是對齊模型和人類的價值觀，試想一下，如果我們不知道模型的內部機制，那麼如果未來有一天我們創造了一個比人類聰明，且逃脫人類監管的 AI 模型，這會是一場堪比科幻小說的災難。所以，我最近展開了一些 Mech Interp 的研究，我預計會通過 Anthropic、DeepMind 等團隊關於模型內部機制的研究，以及從事相關主題的研究，來理解 AI 模型的機制。


我想深入理解 AI 模型內部到底是如何運作的——也就是打破這個「黑盒子」。

目前的 AI 研究很大程度上依賴試錯（trial and error）。我們知道怎麼訓練模型讓它變強，但常常無法解釋為什麼某個改動有效，或為什麼它會突然產生幻覺。這讓我很不安：如果我們未來的社會運作越來越依賴 AI，但我們卻不理解它的決策路徑，那麼真正的 AI 安全（AI Safety）就無從談起。

為了達成這個目標，我正投入於 Mechanistic Interpretability 的研究。我不僅研讀 Anthropic 和 DeepMind 關於 Mech Interp 的前沿論文，也開始自己動手做實驗，嘗試逆向工程模型中的神經迴路（Circuits），觀察特定的能力是如何在神經元之間被編碼的。我不希望只是訓練出表現好的模型，我更希望能真正解釋它們的內部邏輯。


---

### 2. Teach us something you learned recently.

<details>
<summary>💡 策略提示（點擊展開）</summary>

展現你能將經驗轉化為洞見的能力。用英文作答並連結到「建模」主題。

</details>

---

**📝 Draft Answer (v1):**

**📝 草稿回答 (中文版):**

最近我學到了一件關於知識生產的悖論：儘管 AI 領域擁有最尖端的工具（GPU、arXiv、Slack），但其最核心的社會結構卻令人驚訝地**中世紀**。

我原以為現代科學是一個工業化的過程——高效率、標準化、可規模化。但進入頂尖實驗室後，我發現它本質上是一個**古老的學徒制 (Ancient Apprenticeship System)**。

為什麼？依據我的觀察，這是因為「顯性知識」（如程式碼、論文）雖然可以透過網路光速傳播，但「隱性知識」（如研究品味、直覺）卻無法被編碼。

我看見資深的學者像古代的工匠大師一樣，帶領著我們這些學徒。他們最寶貴的技能不是「如何解題」，而是「如何選題」——那種在尚未看見數據之前，就能嗅出哪個方向是死路、哪個方向有金礦的直覺。這種直覺只能透過高度密集的**物理在場 (Physical Presence)**，透過觀察大師如何皺眉、如何猶豫、如何否定 99 個想法選中那 1 個來習得。

這讓我意識到，即使在我們試圖創造通用人工智慧的當下，人類智識的最高級傳承，依然依賴著最原始的人際連結形式。這修正了我對「高效率知識工作」的模型：**工具是現代的，但智慧的傳遞依然是古老的。**



Draft Answer (v2):


原本我以為，在這個擁有最強大算力與最先進算法的地方，知識的生產應該是高度工業化、甚至自動化的。但我驚訝地發現，這裡的核心運作模式，本質上卻更接近 15 世紀的工匠作坊 (Midieval Guild)，而非 21 世紀的工廠。

即使我們使用著最新的 GPU，但最關鍵的「研究品味」——如何選題、如何對數據有直覺——依然只能透過最古老的**「師徒制 (Apprenticeship)」**，透過人與人之間高密度的口耳相傳來習得。顯性知識 (Code) 傳播得很快，但隱性知識 (Insight) 依然依賴著原始的社交頻寬。

這讓我意識到，這個實驗室其實是整個人類社會的縮影，揭示了現代化的一個核心特徵：它是不均勻的 (Uneven)。

我們的文明就像是一台「拼裝車」，由三個不同速度的齒輪勉強咬合在一起： (這裡接你的 Backbone)

科技層 (Tech): 是 21 世紀的（光速迭代）。
制度層 (Institution): 是 19 世紀的（為工業時代設計的）。
生物層 (Biology): 是舊石器時代的（適應部落生活的）。
結論： 我在實驗室學到的是，真正的挑戰不在於如何讓科技層跑得更快（那已經夠快了），而在於如何處理這種**「時間差 (Time Lag)」**。我們依然是用著石器時代的大腦，試圖駕馭神一般的科技。

Draft v3:

**📝 草稿回答 (中文版 - 段落式):**

最近我加入了台灣最頂尖的 AI 實驗室，原本以為會進入一個高度工業化、甚至自動化的「知識工廠」。畢竟，我們擁有最強大的 GPU、最先進的算法，知識的生產應該也是高效且可規模化的吧？

但我很快發現，這裡的核心運作模式更像是 15 世紀的工匠作坊，而非 21 世紀的工廠。最關鍵的「研究品味」——如何選題、如何對數據產生直覺——依然只能透過最古老的「師徒制」來習得。程式碼可以透過 GitHub 光速傳播，但真正的洞見，依然依賴著人與人之間高密度的口耳相傳。

這個觀察讓我開始思考一個更大的問題：我們的「現代化」究竟有多徹底？我逐漸意識到，現代化其實是極度不均勻的。我們的科技層是 21 世紀的，遵循摩爾定律以指數級速度狂飆；但我們的制度層——民族國家、民主投票、市場監管——大多還是 19 世紀工業革命時期的產物，為處理「慢速世界」而設計；而我們的生物層，也就是我們的大腦，依然是為了適應 150 人的採集狩獵部落而演化的，充滿了部落主義與零和思維的原始直覺。

所以我學到的是：我們面臨的最大挑戰，不在於如何讓科技跑得更快——那已經夠快了。真正的挑戰在於如何處理這三層之間的「時間差」。我們依然是用著石器時代的大腦，試圖駕馭神一般的科技，行駛在為馬車設計的道路上。


Draft v4
最近我加入了台大最頂尖的 AI Lab，觀察到一個有趣的現象：即使是今天，大學裡的實驗室依然採取類似中世紀的學徒制，由老師帶領學生做研究。這是因為有許多隱性知識——比如怎麼判斷一個研究主題是否值得研究、如何避免研究上的坑——無法透過論文或其他媒介傳播，只能透過人與人之間的口耳相傳來習得。這讓我進一步思考：到底現代化的社會相較於以前有什麼根本差異？

我們今天創造了極為發達的工具（如 GPU、LLM），可以用超越人類的速度處理資訊。但諷刺的是，我們用來「運用這些工具」的制度——像是 peer review、tenure track——依然是幾百年前的設計。更根本的是，那些最關鍵的隱性知識（如研究品味），至今仍無法被規模化傳播。這讓我意識到，我們的工具跑得太快，但我們自己還沒跟上。學術制度可能還需要幾次根本性的變革，而我們在發揮智力槓桿這條路上，還遠遠沒有走到盡頭。

---

### 3. Tell us something you find beautiful.

> 💡 **策略提示：** 這題測試「內省意識」和「價值觀」。避免太通用的答案（日落、大自然）。要具體，並展現你內在的世界。

---

**📝 Draft Answer (v1):**

**📝 草稿回答 (中文版):**

我認為**「反叛 (Defiance)」**是美麗的——具體來說，是人類文明對殘酷自然法則的崇高反叛。

大自然遵循著一套冷酷而高效的法則：「適者生存」。在過去的一百年裡，人類透過科學與極致的資本主義，將這種效率推向了巔峰——我們利用高科技作為槓桿，戰勝了天災與猛獸，將生產力與時間利用率逼近了極限。這很壯觀，但這不是我所謂的美麗。

我認為真正的美麗，誕生於我們決定**拒絕**這種純粹效率的那一刻。

當一個社會選擇為了照顧那些「低產出」的人（天生的貧困者、身心障礙者）而犧牲掉一部分效率時，那是文明最閃耀的瞬間。這是一種**系統性的慈悲**。然而，目前的資本主義機制在追求利益最大化的過程中，往往系統性地忽視了這些沒有籌碼的群體。

這就是我對未來的願景：構建一個不以「利益導向」，而是以「人民為本」的系統。這就是為什麼我投身 AI——我不只把它視為推高生產力上限的工具，更視為一個能**低成本打造社會底層防護網 (Social Floor)** 的機會。利用技術的槓桿，讓我們終於有能力在不崩潰的前提下，實現這種「反效率」的溫柔。


我認為最美麗的事物，是**「人性光輝對抗殘酷命運」**的那一刻。
 
具體來說，是當災難降臨時——無論是火災、地震還是戰爭——那些本可以逃生的人，選擇轉身面對危險，為了拯救陌生人而犧牲自我。這種行為在生物學上是完全不合理的，違反了所有「適者生存」的本能。但正是在這種極限的壓力下，人性的光輝才最為耀眼：它證明了我們不僅僅是生存機器，我們擁有敢於挑戰命運、超越生死的道德勇氣。
 
但我必須澄清：**我並不歌頌犧牲本身**。我不認為任何人的生命應該被當作代價。相反，這種美麗總是讓我感到心痛。
 
真正讓我動容的，是用自由意志去選擇「非理性」的善良。在這個往往只獎勵「效率」與「利益」的世界裡，這種選擇提醒了我：有些東西的價值是無法被計算的。這種對人性的極致捍衛，不僅美麗，更是我心中文明存在的終極理由。


---

### 4. Analyze for us the purpose of your major (or your current field of study/pursuit).
*What is it trying to teach or do in the world? How does it seek to do so?*

<details>
<summary>💡 策略提示（點擊展開）</summary>

這題測試「建模能力」——你能否跳出來看你領域的 meta-purpose？

</details>

---

**📝 Draft Answer (v1):**

**📝 草稿回答 (中文版):**

我的領域是 **AI 與自然語言處理 (NLP)**。讓我從三個層次來分析它的目的：

**表層目的：** 建立能處理和生成人類語言的系統——翻譯、搜尋、對話。

**深層目的：** 連結人類認知與機器能力之間的鴻溝。語言是人類編碼知識、協調行動和傳承文化的方式。NLP 試圖讓這些龐大的人類意義寶庫能為計算所用。

**批判視角——這個領域假設了什麼，又錯過了什麼？**

這個領域隱含地假設語言可以透過文本中的統計模式來建模。但在台灣原住民語言翻譯計畫的工作經驗教會了我這個假設的侷限性。對於擁有口述傳統的低資源語言，根本沒有足夠的文本數據。這個領域的方法——在英文、中文和其他「數據豐富」的語言上訓練出來的——可能在不經意間編碼了一種語言帝國主義。

同樣地，我在台灣國家級 LLM 專案 (TAIDE) 的經驗揭示了一種張力：這個領域優化的是 **能力 (Capability)**（跑分、速度、流暢度），而 **安全 (Safety)** 往往是事後才被考慮的。NLP 目前的實踐目的，是讓語言模型變得更強大。但也許更深層的目的應該是：讓它們與人類價值更**對齊 (Aligned)**。

這就是為什麼我現在專注於 AI Safety——不只是作為一個獨立的子領域，而是作為這個領域核心目的必要的重新定位。

Draft v2:

其實我在想要不要把領域定義在 AI，而不是 NLP 或者 Speech（儘管我現在略專注在這兩種）。

其實我一開始會進入這個 field，是因為我覺得 AI 很神奇，和其他 computer science 不同的是，特別是比如系統和網路通訊等等更關注計算機系統的效率，而 AI可以實現一些魔法一般的能力。我感覺 AI 就像是人類一樣，什麼都能做到。

後來我發現 AI 好像也沒有那麼萬能，大部分的 AI 表現的比優秀的人類還差，只有少部分類似 alpha go 的模型超越了人類。當時大部分的模型只在相對簡單的 task 上超越人類，比如 image classification 等。

直到 LLM 的出現，我發現 AI 開始有能力在通用的任務上也表現得比人類還好。比如 writing，可以幫助我寫出英語母語者寫的文章。當然，最大的 insight 在於 LLM 中的 large，因為更大的模型湧現出更強的 capability。

當然，即時現在的 LLM 發展已經足夠成熟了，但現在依然距離終點——AGI 還有很長遠的距離，像是最近比較流行的 multi-modal LLM，其實還是有顯著的 modality gap，模型還是沒有辦法像人類一樣好的理解多模態的資訊。不過，我對這個領域依然還有信心，這也是為什麼我會想繼續深耕像是 Multi-modality, AI Safety 的領域。

Draft v3:

如果說大多數電腦科學領域（如網路、系統）追求的是「計算的效率」，那麼 AI 領域追求的則是**「計算的生命」**。

我最初被這個領域吸引，是因為它承諾了一種幾乎是造物主般的能力：創造一種能夠思考、能夠像人類一樣感知世界的代理人 (Agent)。這不僅僅是工具的優化，這是物種層面的創造。

然而，這條路比想像中艱難。早期的模型像是笨拙的模仿者，只能在極窄的任務（如圖像分類）上勝過人類，卻沒有靈魂。直到 LLM 出現，我看見了「通用性」的曙光——模型開始能夠在它沒見過的任務上展現能力，這就是我們夢寐以求的**泛化 (Generalization)**。

但我認為目前的 AI 還沒辦法像人類一樣理解這個世界。它擁有強大的語言能力，卻對物理世界缺乏真實的感知。這就是為什麼我認為 AI 下一階段的核心目的是 **Embodiment（具身化）** 與 **Multimodality（多模態）**。

這個學科的終極目的，不僅是為了自動化工作，而是為了解開宇宙中最大的謎題之一：**智慧是如何從無機物中湧現的？** 我們是透過「建造它」來「理解它」。這是我深耕這個領域的動力——我想要參與建構這個非人物種 (Non-human Intelligence) 的過程。

### 5. List at least 50 questions you have about the world.
*Feel free to exceed the recommended 300 word limit for this question.*

> 💡 **策略提示：** 這是展現「智識好奇心」最重要的題目。以下清單結合了你的 AI 背景、社會觀察與哲學思考。

---

**📝 Draft Answer (v1):**

**📝 草稿回答 (中文版):**
*(注意：最終提交建議使用英文，這裡先用中文呈現以利審閱)*

**關於後資本主義與制度設計**
1. 資本主義優化了效率，但它未能將「人類尊嚴」計入成本。是否存在一種經濟學數學模型，能將人類福祉視為限制條件 (Constraint) 而非外部性 (Externality)？
2. 如果我們利用「機制設計 (Mechanism Design)」從零開始設計一個社會，我們會重新發明民主嗎？還會找到一個更好的演算法來聚合集體偏好？
3. 「效率」永遠是一種美德嗎？或者一個極度高效的社會是否註定會變得脆弱且缺乏彈性？
4. 為什麼貧窮是昂貴的？我們能否設計一個「社會穩定函數」來逆轉這種動力學？
5. 「民族國家 (Nation-state)」是人類政治組織的最終形式，還是一個過渡階段？

**關於 AI、教育與未來**
6. 如果 AI 將知識的邊際成本降為零，學校的教學方式會有什麼變化？
7. AI 會解決教育中的「雙標準差問題 (Two-sigma problem)」（人人都有家教），還是會進一步加大教育的不平等？
8. 人類進步的瓶頸是「智力」，還是「協調 (Coordination)」？
9. 當我們將更多的認知勞動外包給機器時，人類注意力的「肌肉」會發生什麼變化？
10. 下一場重大衝突會是為了爭奪數據、算力，還是能源？

**關於人性、幸福與意義**
11. 幸福是一個基於比較的零和遊戲嗎？如果每個人都變富有，是否就沒有人覺得自己富有？
12. 如果我們可以「工程化」同理心，讓它成為一種系統預設值（比如自動財富重分配），我們是否願意放棄個人行善的道德滿足感？
13. 「同理心」是一種有限資源嗎？我們能否從結構上設計社會，使其更依賴系統性的公平，而非個人的同理心？

**關於成功、天賦與歷史**
14. 有多少「成功」只是偽裝成「毅力 (Grit)」的「倖存者偏差」？
15. 是「偉人」創造了歷史，還是歷史創造了對「偉人」的需求？
16. 為什麼有些極度聰明的人一事無成，而有些資質平平的人卻改變了世界？「能動性 (Agency)」是獨立於智商之外的特質嗎？

**關於政治與民主**
17. 網際網路是否必然會導致社會極化？或者我們目前的極化只是特定廣告驅動演算法的結果？

18. 我想知道 10 年後對人類最重要的事情是什麼？
19. 我們能否設計出一種「後民族國家」的身份認同，既能保留部落歸屬感的溫暖，又能維持全球協調所需的凝聚力？
20. 真正的「包容性」社會看起來是什麼樣子的？是一個大熔爐（所有差異都消失），還是一個馬賽克（差異並存但互不干擾），或者是一種全新的、我們尚未命名的幾何結構？
21. AI 是否能成為唯一真正公正的法官——一部在數學上無法被賄賂、且對種族和財富完全「色盲」的機器？或者這只是一個危險的技術官僚幻想？
22. AI 究竟是瀕危語言的「諾亞方舟」（幫忙保存與復興），還是它們的「滅絕加速器」（因為每個人都開始用 AI 的強勢語言溝通）？
23. AI 究竟會成為偉大的「均衡器 (Great Equalizer)」（讓每個人都有家教/醫生），還是成為究極的「放大器 (Ultimate Amplifier)」，讓擁有資本的人與沒有的人之間的鴻溝，大到變成兩個不同的物種？
24. 如果我們要為 5000 年後的文明（或外星生物）留下一個「時間膠囊」，我們應該留下巴哈的音樂來展示美，還是維基百科來展示知識？
25. 數位親密關係 (Digital Intimacy) 是解決孤獨的解藥，還是一種會讓我們喪失與真實人類連結能力的「精神鴉片」？
26. 未來 AI 是否會完全取代人類研究者？如果是，人類在「知識創造」的迴路中還剩下什麼角色？是「提出問題的人」，還是僅僅是「被餵養答案的消費者」？
27. 如果我們能將意識（以及愛因斯坦等偉人）上傳到雲端，這會加速人類發展，還是創造一個永遠由「不死的長者」統治的停滯社會 (Gerontocracy)？
28. 如果 AI 音樂比貝多芬還好聽，「人類創作」會變成一種像「手工藝品」一樣的奢侈標籤嗎？
29. 如果 AI 產生了比人類更高等的智慧，人類還有辦法維持相同的社會地位嗎？還是我們會像尼安德塔人一樣被邊緣化？
30. 是否有辦法真正教會 AI 「人性」？或者我們只是在教它如何完美地「模仿」人性？
31. 如果人類能夠通過更換機器肢體或器官來獲得永生與強壯，你是否會選擇拋棄肉體？這條「忒修斯之船」的界線在哪裡？
32. 如果我們可以透過腦機介面直接「下載」知識（像駭客任務一樣），這會引爆科技奇點，還是會讓我們因為缺乏「學習過程中的磨練」而變得智識脆弱？
33. 如果人類的所有惡行都能被量化和記錄（如《黑鏡》的社會信用評分），這會創造一個道德完美的社會，還是一個令人窒息的全景監獄？
34. 如果世界上所有人類沒有語言隔閡（重回巴別塔之前），這會帶來全球和平，還是會因為失去了「文化緩衝區」而加速衝突？
35. 為什麼事實 (Facts) 往往說服不了人，但故事 (Stories) 可以？這是大腦的 Bug 還是 Feature？
36. 民主制度是否根本無法處理「超複雜系統」（如氣候變遷）？因為選民的注意力廣度只有 4 年，但問題的時間跨度是 100 年。
37. 如果 AI 判斷「人類的存在」對地球整體生態是負資產（邏輯上正確），我們有什麼論點可以反駁它？除了「我們想活下去」這種自私的理由？
38. 現在有什麼事情是我們覺得理所當然（如吃肉、監獄制度），但 100 年後的人會覺得我們是野蠻人的？





---

### LLM Usage

**If you used LLMs (Large Language Models) in crafting your responses, how did you use it?**
*If you didn't use LLMs, we are also curious as to why you chose not to, or feel free to leave this section blank.*

> 💡 **策略提示：** 誠實透明。建議的表達方式：
>
> *「我使用 Claude 來幫助我組織思緒和提升表達清晰度，但所有的想法和經驗都是我自己的。我發現 LLM 在迭代草稿時很有用，類似於和同事討論想法。」*

---

**📝 草稿回答 (中文版):**

我使用了 LLM 作為我的**「智識陪練 (Intellectual Sparring Partner)」**和**編輯助手**，而非單純的內容生成器。

具體過程如下：

1.  **構思與挑戰 (Ideation & Challenge):** 我使用 LLM 來進行蘇格拉底式的對話。例如在發想 Q5 的 50 個問題時，我先提出了我關注的核心領域（如社會制度、後資本主義），然後要求 LLM 挑戰我的盲點，幫助我將模糊的直覺轉化為具體的探問。

2.  **翻譯與潤飾 (Translation & Refinement):** 由於我習慣先用中文思考，我撰寫了所有回答的原始中文草稿，確實捕捉我的個人經驗（如 TAIDE、AI Safety Group）。接著我使用 LLM 協助將這些想法翻譯成精確、細膩的英文，確保語氣既專業又真誠。

3.  **後設反思 (Meta-Reflection):** 我也將 LLM 作為一面鏡子，詢問它我的回答反映出什麼樣的價值觀模型，以此來檢視我是否真實地表達了自己。

## Additional Comments

**Some miscellaneous questions that you can help us prepare the program better.**

- **Would you like to recommend someone else who you think should attend this program as well?**
  *(Include their full name, email, and rationale)*

  > *(待你補充)*

- **How did you hear about us?**

I learned about the Compass Fellowship through recommendations from **Alvin Lau** and **Sin-tshong Tsu**.

- **Anything else you would like to share with us?**

---

**📝 Draft Answer (v1):**

**📝 草稿回答 (中文版):**

我今年 27 歲——略高於你們典型的年齡範圍。我想直接說明這一點。

我申請是因為我相信我的經歷能為這個群體提供一個有價值的視角：

- 作為 **台灣國家級 LLM 專案 (TAIDE)** 的工程師，我親眼見證了一個耗資千萬美金的政府計畫如何在國家規模上應對「能力」與「安全」之間的張力。
- 作為 **Taiwan AI Safety Reading Group 的組織者**，我一直在致力於建立橋樑，連結那些在乎對齊 (Alignment) 的研究者，以及那個往往將速度置於安全之上的廣大台灣科技社群。
- 曾在 **產業界**（AI 新創）和 **學術界**（台大研究室）工作過，這讓我發展出了一套框架，能建模不同機構如何以不同的方式看待風險與創新。

我正處於一個積極反思我想成為什麼樣的研究者——以及什麼樣的人——的階段。Compass Fellowship 強調的內省與建模對我來說正是時候：我花了很多年建立技術能力，現在我想發展運用這些能力的智慧。

我很興奮能有機會與更年輕的參與者一起學習。我希望我的經驗對他們有用，也確信他們新鮮的視角會挑戰我的假設。

---

**Contact:** If you have any questions, you can email `contact [at] compassfellowship [dot] app`.